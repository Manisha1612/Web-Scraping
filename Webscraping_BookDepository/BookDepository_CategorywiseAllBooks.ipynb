{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book depository web scraping\n",
    "Website : https://www.bookdepository.com\n",
    "In this project we are collecting all books from the website using Python BeautifulSoup library. \n",
    "The website is having different category books.\n",
    "The result data is saved into a CSV file, which could be used for data analysis purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get clean books data and store into list\n",
    "# store all lists into dictionary and return it\n",
    "def getOnePageCleanBooksData(books, url):\n",
    "    titles = []\n",
    "    authors = []\n",
    "    bookPublishDates = []\n",
    "    bookFormats = []\n",
    "    salePrices = []\n",
    "    oldPrices = []\n",
    "    for book in books:\n",
    "        \n",
    "        # to get book title\n",
    "        title = book.find('h3', class_ = 'title')\n",
    "        titles.append(title.text.strip('\\n '))\n",
    "\n",
    "        # to get author name\n",
    "        author = book.find('p', class_ = 'author')\n",
    "        authors.append(author.text.strip(' \\n '))\n",
    "\n",
    "        # to get book published date\n",
    "        bookPublishedDate = book.find('p', class_= \"published\")\n",
    "        bookPublishDates.append(bookPublishedDate.text.strip())\n",
    "\n",
    "        # to get book format\n",
    "        bookFormat = book.find('p', class_= \"format\")\n",
    "        bookFormats.append(bookFormat.text.strip())\n",
    "\n",
    "        # to get book sale price\n",
    "        price = book.find('span', class_=\"sale-price\")\n",
    "        if price:\n",
    "            price_text = book.find('span', class_=\"sale-price\").get_text()\n",
    "            # remove extra char from value e.g. $\n",
    "            salePrice = (re.findall(r'\\d+[.,]\\d+',price_text))\n",
    "            salePriceFloat = float(salePrice[0].replace(',','.'))\n",
    "            price = salePriceFloat\n",
    "        salePrices.append(price)\n",
    "        \n",
    "        \n",
    "        # to get original/old book price\n",
    "        rrpPrice = book.find('span', class_ = \"rrp omnibus\")\n",
    "        if rrpPrice:\n",
    "            rrpPrice_text = book.find('span', class_=\"rrp omnibus\").get_text()\n",
    "            # remove extra char from value e.g. $\n",
    "            oldPrice = (re.findall(r'\\d+[.,]\\d+',rrpPrice_text))\n",
    "            oldPriceFloat = float(oldPrice[0].replace(',','.'))\n",
    "            rrpPrice = oldPriceFloat\n",
    "       \n",
    "        if not rrpPrice:\n",
    "            rrpPrice = price\n",
    "        \n",
    "        oldPrices.append(rrpPrice)\n",
    "        \n",
    "        category = url.split(\"/\")[-1]\n",
    "        \n",
    "    booksDict = {\n",
    "    'Title': titles,\n",
    "    'Author': authors,\n",
    "    'Published date': bookPublishDates,\n",
    "    'Format': bookFormats,\n",
    "    'Sale Price': salePrices,\n",
    "    'Old Price': oldPrices,\n",
    "     'Category':   category\n",
    "        \n",
    "    }   \n",
    "    return booksDict\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get soup result from one url\n",
    "def getSoup(url):\n",
    "    results = requests.get(url)\n",
    "    if(results.status_code == 200):\n",
    "        soup = BeautifulSoup(results.text, 'lxml')\n",
    "        books = soup.find_all('div', class_='book-item')\n",
    "    return books    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get all book category links from Main/Home webpage\n",
    "\n",
    "def getCategroywiseBooksLinks():\n",
    "    URL = 'https://www.bookdepository.com/'\n",
    "\n",
    "    # Fetch all the HTML source from the url\n",
    "    response = requests.get(URL)\n",
    "\n",
    "    # Parse HTML and extract links\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    #links = soup.select('a')\n",
    "    links = soup.find_all('a')\n",
    "    # To find all category wise links\n",
    "    searchLinks = []\n",
    "    for link in links:\n",
    "        if link.get('href') != None:\n",
    "            if 'https://' not in link.get('href'):\n",
    "                searchLinks.append('https://www.bookdepository.com' + link.get('href')) # Convert relative URL to absolute URL\n",
    "\n",
    "    link_to_check = 'https://www.bookdepository.com/category'\n",
    "    categori_Links = []\n",
    "    for searchLink in searchLinks:\n",
    "\n",
    "        if link_to_check in searchLink:\n",
    "            categori_Links.append(searchLink)\n",
    "            \n",
    "    return categori_Links        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Art-Photography\n",
      "Audio-Books\n",
      "Biography\n",
      "Business-Finance-Law\n",
      "Childrens-Books\n",
      "Computing\n",
      "Crafts-Hobbies\n",
      "Crime-Thriller\n",
      "Dictionaries-Languages\n",
      "Entertainment\n",
      "Fiction\n",
      "Food-Drink\n",
      "Graphic-Novels-Anime-Manga\n",
      "Health\n",
      "History-Archaeology\n",
      "Home-Garden\n",
      "Humour\n",
      "Medical\n",
      "Mind-Body-Spirit\n",
      "Natural-History\n",
      "Personal-Development\n",
      "Poetry-Drama\n",
      "Reference\n",
      "Religion\n",
      "Romance\n",
      "Science-Geography\n",
      "Science-Fiction-Fantasy-Horror\n",
      "Society-Social-Sciences\n",
      "Sport\n",
      "Stationery\n",
      "Teaching-Resources-Education\n",
      "Technology-Engineering\n",
      "Teen-Young-Adult\n",
      "Transport\n",
      "Travel-Holiday-Guides\n",
      "Books-for-Ages-0-2\n",
      "Books-for-Ages-3-5\n",
      "Books-for-Ages-6-8\n",
      "Books-for-Ages-9-11\n",
      "Teen-Young-Adult\n",
      "Autobiography-General\n",
      "Fantasy\n",
      "Business-Management\n",
      "Military-History\n",
      "Childrens-Books\n",
      "Fiction\n",
      "Crime\n",
      "Graphic-Novels-Anime-Manga\n",
      "Fiction\n",
      "Stationery\n",
      "Childrens-Books\n",
      "Fiction\n",
      "Graphic-Novels-Anime-and-Manga\n",
      "Food-and-Drink\n",
      "Crafts-and-Hobbies\n",
      "Art-and-Photography\n",
      "Biography\n",
      "Crime-and-Thriller\n"
     ]
    }
   ],
   "source": [
    "categorywiseBooksUrl = getCategroywiseBooksLinks() #collect all book category url\n",
    "\n",
    "combineDF = []\n",
    "dataframe_collections = {} \n",
    "#url = 'https://www.bookdepository.com/category/2/Art-Photography'\n",
    "for url in categorywiseBooksUrl:\n",
    "    books = getSoup(url)\n",
    "    booksDict = getOnePageCleanBooksData(books, url)\n",
    "    booksData = pd.DataFrame(booksDict)  # convert one category books data dictionary into dataframe\n",
    "    combineDF.append(booksData)\n",
    "    \n",
    "    category = url.split(\"/\")[-1] # to get category from url\n",
    "   # dataframe_collections[category]= booksData\n",
    "    print(category)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get all categories from url\n",
    "categoryLists = [] \n",
    "for link in categorywiseBooksUrl:\n",
    "    categoryLists.append(link.split(\"/\")[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.concat(combineDF)  # combine list of dataframes into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9238, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fiction                           1012\n",
       "Childrens-Books                    675\n",
       "Graphic-Novels-Anime-Manga         590\n",
       "Stationery                         454\n",
       "Biography                          316\n",
       "Graphic-Novels-Anime-and-Manga     295\n",
       "Mind-Body-Spirit                   261\n",
       "Food-and-Drink                     238\n",
       "Food-Drink                         238\n",
       "Poetry-Drama                       227\n",
       "Art-Photography                    218\n",
       "Art-and-Photography                218\n",
       "Home-Garden                        210\n",
       "Crime-Thriller                     207\n",
       "Dictionaries-Languages             207\n",
       "Crime-and-Thriller                 207\n",
       "Teaching-Resources-Education       204\n",
       "History-Archaeology                194\n",
       "Personal-Development               186\n",
       "Audio-Books                        167\n",
       "Science-Geography                  161\n",
       "Religion                           159\n",
       "Transport                          157\n",
       "Sport                              154\n",
       "Humour                             145\n",
       "Health                             139\n",
       "Computing                          136\n",
       "Entertainment                      126\n",
       "Crafts-Hobbies                     124\n",
       "Crafts-and-Hobbies                 124\n",
       "Military-History                   121\n",
       "Medical                            120\n",
       "Technology-Engineering             114\n",
       "Business-Finance-Law               112\n",
       "Travel-Holiday-Guides              111\n",
       "Science-Fiction-Fantasy-Horror     109\n",
       "Business-Management                104\n",
       "Romance                            103\n",
       "Reference                           83\n",
       "Natural-History                     82\n",
       "Society-Social-Sciences             76\n",
       "Autobiography-General               75\n",
       "Fantasy                             69\n",
       "Teen-Young-Adult                    60\n",
       "Books-for-Ages-6-8                  30\n",
       "Books-for-Ages-0-2                  30\n",
       "Crime                               30\n",
       "Books-for-Ages-9-11                 30\n",
       "Books-for-Ages-3-5                  30\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataFrame to CSV file -( creat file before then execute )\n",
    "result.to_csv('AllBookData.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
